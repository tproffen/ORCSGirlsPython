{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Activity 3 -- Most popular words.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tproffen/ORCSGirlsPython/blob/master/TextMining/Activity%203%20--%20Most%20popular%20words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dTBQPmZeK3Q8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://github.com/tproffen/ORCSGirlsPython/blob/master/TextMining/Images/PoweredTechGirlz.png?raw=1\" width=\"15%\" align=\"right\">\n",
        "\n",
        "# Activity 3: Text Mining Harry Potter - Most Popular Words\n",
        "\n",
        "We will be using data provided by [Bradley Boehmke](https://github.com/bradleyboehmke/harrypotter).\n",
        "\n",
        "The goal of this class is to do a textual analysis of the seven Harry Potter books. We will use Python to discover some interesting insights that maybe nobody else in the world has realized about the Harry Potter books! In this activity we will find the most popular words and combination of words in book 1.\n",
        "\n",
        "<img src=\"https://github.com/tproffen/ORCSGirlsPython/blob/master/TextMining/Images/book_covers.png?raw=1\" width=\"60%\" align=\"left\">"
      ]
    },
    {
      "metadata": {
        "id": "azhaxyfaK4vP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!curl -s -o setup.sh https://raw.githubusercontent.com/tproffen/ORCSGirlsPython/master/TextMining/Helpers/setup_activity3.sh\n",
        "!bash setup.sh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yfm1zyqVK3Q9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import Helpers\n",
        "from Helpers.load_data import *\n",
        "from Helpers.plot_data import *\n",
        "from Helpers.clean_data import *\n",
        "from collections import Counter\n",
        "#from wordcloud import WordCloud, STOPWORDS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "RkDEiFe_K3Q_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Most popular words\n",
        "\n",
        "## Clean up\n",
        "\n",
        "We will try to find out which words are the most popular in each book.\n",
        "\n",
        "We already know how to split each book into words, but this time we will need to do two additional steps.\n",
        "\n",
        "First, look at the following piece of text:"
      ]
    },
    {
      "metadata": {
        "id": "1PIf_PzOK3RA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text = (\n",
        "    'Hagrid: \"You are a wizard, Harry\" '\n",
        "    'Harry: \"I am a what?\" '\n",
        "    'Hagrid: \"A wizard, Harry\" '\n",
        ")\n",
        "print(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wBeyu__OK3RC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "How can we find the most popular words in this piece of text?\n",
        "\n",
        "As it turns out, Python has another neat function which we can use to do that. It's called a `Counter`. You can give `Counter` a list of words and it will count how many times does each word appear. \n",
        "\n",
        "To do that, we first need a list of words. In the cell below, split the text into words and assign the result to a new variable called `words`:"
      ]
    },
    {
      "metadata": {
        "id": "EfCJ-iDrK3RD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words = text.split()\n",
        "print(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v5IgarR0K3RF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that we have separate words, we can pass those to a `Counter`:"
      ]
    },
    {
      "metadata": {
        "id": "Os_XYpS4K3RG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Counter(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6pzqQQ2iK3RJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What happened? `Counter` counted the words \"Harry\" and \"Harry:\" as two separate words. It also counted \"A\" and \"a\" as two separate words.\n",
        "\n",
        "To fix this, we will need to remove all characters from the text which are not letters, and conver the text to lowercase.\n",
        "\n",
        "First, lets remove special characters. We prepared a helper function that you can use to remove those special characters. It's called `remove_special_characters` :) This is how it works:"
      ]
    },
    {
      "metadata": {
        "id": "vs0kH4gsK3RK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "my_word = '\"Harry!\"'\n",
        "\n",
        "print(\"Original word:\", my_word)\n",
        "\n",
        "clean_word = remove_special_characters(my_word)\n",
        "\n",
        "print(\"Clean word:\", clean_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qUFa2gW_K3RN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Can you do this for all words in our text? Try to do that in the field below:"
      ]
    },
    {
      "metadata": {
        "id": "QZTUXIjhK3RO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clean_words = []\n",
        "\n",
        "for word in words:\n",
        "    clean_words.append(remove_special_characters(word))\n",
        "    \n",
        "print(clean_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fk5ubBauK3RR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets try the counter again:"
      ]
    },
    {
      "metadata": {
        "id": "Z6ZRLAKKK3RT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Counter(clean_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PAG0vT2nK3RW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We still have some uppercase and lowercase words that make Python think 'A' and 'a' are two separate words. We need to convert everything to lowercase.\n",
        "\n",
        "In Python that can be done using a function called `lower`:"
      ]
    },
    {
      "metadata": {
        "id": "XYhwlIVLK3RX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"HELLO\")\n",
        "print(\"HELLO\".lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bIZ8Kf0SK3RY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets do this for the words in our text:"
      ]
    },
    {
      "metadata": {
        "id": "55wEtcK4K3RZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lowercase_words = []\n",
        "\n",
        "for word in clean_words:\n",
        "    lowercase_words.append(word.lower())\n",
        "    \n",
        "print(lowercase_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gew1tKJ6K3Rb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's try the counter again:"
      ]
    },
    {
      "metadata": {
        "id": "bMH9aN9PK3Rb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Counter(lowercase_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BnWPZYNGK3Rd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# It worked!"
      ]
    },
    {
      "metadata": {
        "id": "JwLOUF_DK3Rd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Most popular words\n",
        "\n",
        "Let's try to apply this to the first book. First, let's load the book:"
      ]
    },
    {
      "metadata": {
        "id": "jwxBWALTK3Re",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "book = load_book_1()\n",
        "\n",
        "print(book[0:500])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DFhvcv4fK3Rh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's do what we just learned: split the book to words, turn all words to lowercase and remove special characters. To avoid writing the same code again, we prepared another helper function for you that does all the cleanup we need. It's called `make_clean_words`:"
      ]
    },
    {
      "metadata": {
        "id": "ywj9uKsbK3Rh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clean_words = make_clean_words(book)\n",
        "    \n",
        "print(clean_words[0:26])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3rO8odJUK3Rj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We just cleaned the whole book one!\n",
        "\n",
        "We can use `Counter` to count occurences of all words in the book!\n",
        "\n",
        "The list would be veeeeeeeeeeery long! So let's ask counter to only give us the 10 most common words:"
      ]
    },
    {
      "metadata": {
        "id": "rGJNZ4puK3Rk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Counter(clean_words).most_common(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oQV4zTGeK3Rm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# That's it! The 10 most common words in book 1!\n",
        "\n",
        "Something happened though. Are all of the words useful to us? Is it useful knowing that \"the\" is the most common word?\n",
        "\n",
        "In English, words like \"the\", \"a\", and \"I\" appear very often, but don't give us any useful information. The frequently appearing words are called \"stopwords\". They are important because they help to structure our sentences, but they don't tell us anything about the meaning of the text.\n",
        "\n",
        "That's why in Text Mining we usually remove those words.\n",
        "\n",
        "We prepared another helper function that you can use -- this function removes all stopwords from a list of words. It's called `remove_stopwords`:"
      ]
    },
    {
      "metadata": {
        "id": "YyhRrm6wK3Rn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Before:\", clean_words[0:26])\n",
        "print()\n",
        "\n",
        "no_stopwords = remove_stopwords(clean_words)\n",
        "\n",
        "print(\"After:\", no_stopwords[0:26])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LBrnVz-_K3Rq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's try the `Counter` again:"
      ]
    },
    {
      "metadata": {
        "id": "Zwi0eGupK3Rq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Counter(no_stopwords).most_common(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SG7DiHwcK3Rs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Yay! That worked!\n",
        "\n",
        "Can you tell me who are the most frequently mentioned students in book 1?\n",
        "\n",
        "Let's try to do this for book 2!\n",
        "\n",
        "We prepared a bit of code to help you. Fill in the missing lines:"
      ]
    },
    {
      "metadata": {
        "id": "plYBjiq-K3Rs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "book = load_book_2()\n",
        "\n",
        "clean_words = make_clean_words(book)\n",
        "\n",
        "no_stopwords = remove_stopwords(clean_words)\n",
        "\n",
        "Counter(no_stopwords).most_common(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZEO_v8PQK3Ru",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Remember that in the previous activity we used a function called `plot` to visualize the results? Let's try that again:"
      ]
    },
    {
      "metadata": {
        "id": "qQ4VPDfAK3Rv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "top_words = Counter(no_stopwords).most_common(10)\n",
        "\n",
        "plot_words(top_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8EUhbPAjK3Rw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Try this for other books by changing the fields above."
      ]
    },
    {
      "metadata": {
        "id": "6D0JmiCXK3Rw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Word pairs\n",
        "\n",
        "What about combinations of words?\n",
        "\n",
        "So far we were looking at a single word at a time. What if we want to find how often do two words appear in the text together? For example \"professor lockhart\".\n",
        "\n",
        "Remember our text from the start of this activity?"
      ]
    },
    {
      "metadata": {
        "id": "3x05WtvnK3Rx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BNRwXxXRK3Ry",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We prepared a function which takes a list of words and turns those words into pairs:"
      ]
    },
    {
      "metadata": {
        "id": "IfGfz3hnK3Rz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words = text.split()\n",
        "\n",
        "pairs = get_word_pairs(words)\n",
        "\n",
        "Counter(pairs).most_common(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "RhO0g-FoK3R2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's do this for book 1."
      ]
    },
    {
      "metadata": {
        "id": "rQWyDFWDK3R2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "book = load_book_1()\n",
        "\n",
        "clean_words = make_clean_words(book)\n",
        "    \n",
        "no_stopwords = remove_stopwords(clean_words)\n",
        "\n",
        "word_pairs = get_word_pairs(no_stopwords)\n",
        "\n",
        "Counter(word_pairs).most_common(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U2A1X8DMK3R5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_words(Counter(word_pairs).most_common(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N7y_tILxK3R7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Word Clouds\n",
        "\n",
        "You might remember word clouds from the last class. All we need to do is read the desired book with our loading routine. For book one, we use `load_book_1()` and then create the wordcloud like we did in the Python class.  \n",
        "\n",
        "After running it, change the code and create word clouds for all the different books. You can also create a new cell using the menu `Insert` -> `Insert cell below` and copy the code, so you can have a word cloud for all seven books in this one notebook."
      ]
    },
    {
      "metadata": {
        "id": "2JJFgI7LLtmh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install wordcloud"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pYds8RwsK3R8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "book = load_book_1()\n",
        "wc = WordCloud(width=1000, height=1000, background_color=\"white\", stopwords=STOPWORDS).generate(book)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(wc);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B1HnryI0K3R-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Yeak you made it through activity 3.\n",
        "\n",
        "Feel free to experiment with the notebook to learn even more about the Harry Potter books. For example, you can try other word clouds or finding most common word pairs in the other books."
      ]
    },
    {
      "metadata": {
        "id": "v096APeZK3R-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}